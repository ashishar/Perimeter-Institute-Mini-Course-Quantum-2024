{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ashishar/qbook/blob/master/Rydberg_reconstruction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generative Modelling\n",
        "# Tutorial 1: Rydberg wavefunction reconstruction using restricted Boltzmann machines\n",
        "\n",
        "Perimeter Institute\n",
        "\n",
        "Quantum and AI Career Trajectories Mini-Course\n",
        "\n",
        "May 22, 2024\n",
        "\n",
        "Authors: Roger Melko, Ejaaz Merali and Mohamed Hibat-Allah"
      ],
      "metadata": {
        "id": "Qj5-u8GamIjC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Start by reading the text and code below.\n",
        "You will  find a total of 6 exercises (plus 2 additional \"bonus\" challenge exercises) in the \"Exercises\" section below."
      ],
      "metadata": {
        "id": "z5B1OoktnjvU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Overview and goal"
      ],
      "metadata": {
        "id": "8iI8frUighrL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The aim of this tutorial is to show you how to train a Restricted Boltzman Machine (RBM) to reconstruct the wavefunction of an array of Rydberg atoms whose exact state is unknown. We will show an example with an array of 8 atoms. Each of the 8 atoms can be in the groundstate (0 state) or Rydberg state (1 state). You can read more about Rydberg atoms arrays here: https://arxiv.org/pdf/2002.07413. You can find the expression of the Hamiltonian in Section. IV."
      ],
      "metadata": {
        "id": "OaY_PvXDgglI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The Training Data"
      ],
      "metadata": {
        "id": "TpfIgUjwgo__"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now $\\Omega$ and $\\delta$ are 2 parameters of the Rydberg Hamiltonian (see https://arxiv.org/pdf/2107.00766.pdf).\n",
        "In this example, we fix $\\Omega=1.0$.\n",
        "Then for each\n",
        "$\\delta \\in \\{ 1.00, 1.02, 1.04, 1.06, 1.08, 1.10, 1.12, 1.14, 1.16, 1.18, 1.20 \\}$,\n",
        "we obtain 10,000 measurements of the state of the 8 atoms.\n",
        "Thus there are 11 training datasets for each $\\delta$ and each training dataset has 10,000 rows (for the 10,000 measurements) and 8 columns as there are 8 Rydberg atoms in the array.\n",
        "\n",
        "The training data is stored at https://github.com/PIQuIL/EssiQQurke/tree/main/data.\n",
        "The training data file for each $\\delta$\n",
        " is given in the `data/nY=8` directory in the `_samples.csv` files."
      ],
      "metadata": {
        "id": "6HXxSs8bgrPq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training the RBM"
      ],
      "metadata": {
        "id": "e8Xw9El3R9lp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The RBM is trained using [QuCumber](https://github.com/PIQuIL/QuCumber). To train we need to specify the number of visible units and some hyperparameters including the number of hidden units.\n",
        "As we have an array of 8 atoms, our input vectors will have 8 elements, and there are 8 visible units.\n",
        "The number of hidden units and the other hyperparameters can be varied for each $\\delta$ to obtain better solutions.\n",
        "More information about the hyperparameters is given in the relevant section of the code below."
      ],
      "metadata": {
        "id": "5-s06TEMR_6a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Checking the accuracy of the model"
      ],
      "metadata": {
        "id": "st_F2s4iSgfm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "After training is done, we get weights and biases of our trained RBM.\n",
        "Recall that we do not know the actual wavefunction.\n",
        "Therefore we cannot compute fidelity, which is a standard matric to evaluate the performance of a model.\n",
        "However, from the original measurements one point functions and two point functions have been calculated. (Note: the one point function and two point functions are described in detail in the relevant section of the code below).\n",
        "Now from the trained RBM (for a particular $\\delta$) we generate `num_samples` = 10,000 samples.\n",
        "From those samples we calculate the one point and two point function data. It can be seen that the data we calculate for the one point and two point function are close to the data in the `_1_pt_fn.csv` and `_2_pt_fn.csv` files for a particular $\\delta$.\n",
        "We use these 2 methods to check how well the distributiton of the samples generated by the RBM resembles the distribution of the measurement."
      ],
      "metadata": {
        "id": "uYqK_GR8Sm-X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Directory structure"
      ],
      "metadata": {
        "id": "J2079gTxFuy6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code below implements the wavefunction reconstruction example for an array of 8 atoms.\n",
        "\n",
        "On https://github.com/PIQuIL/EssiQQurke/:\n",
        "* The `data/` directory contains the training data for different systems which are labelled as `'nY=[number of atoms in the array]'`. Now the `'data/nY =[num_of_atoms_in_array]'` directory contains 3 sets of files for each $\n",
        "delta$, which are the one point function, two point function and the samples.\n",
        "\n",
        "* The `output/` directory contains some of the outputs produced by the code, which are:\n",
        "\n",
        "  1. `reconstructedSample.txt`: This contains the new sampled measurement data produced by the trained RBM.\n",
        "  2. `reconstructedStateAmplitude.txt`: This contains the amplitudes of the reconstructed quantum state in the computational basis.\n",
        "  3. `rydberg_data.pt`: contains the parameters of the trained RBM."
      ],
      "metadata": {
        "id": "mroKL_qUFxC1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Remarks"
      ],
      "metadata": {
        "id": "uaKjWCUFGwM8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this tutorial we train an RBM using measurement data and then sample from the trained RBM to generate more data.\n",
        "The generated data is used to reconstruct the unknown wavefunction.\n",
        "Lastly note that amplitude computation may take some time and thus it may be wise to not do amplitude calculation for $nY>8$\n",
        " systems."
      ],
      "metadata": {
        "id": "JAWeZIdBGzSU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercises"
      ],
      "metadata": {
        "id": "9JiPPUBOG71I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "1. We have seen in Lecture 1 that the RBM probability distribution is given by:\n",
        "$$P_{\\rm RBM} (\\sigma_1^z,\\sigma_2^z, ..., \\sigma_{nY}^z, h_1, \\ldots, h_M)  = \\frac{\\exp ( \\sum_{i=1}^{nY} a_i \\sigma_i^z + \\sum_{j = 1}^M b_j h_j + \\sum_{j,i = 1}^{nY,M} W_{ij} h_i \\sigma^z_j  ) }{ Z_{\\boldsymbol{\\lambda}}},$$ where $\\sigma_i^z \\pm 1$ and $h_j \\pm 1$. Show that the marginalized RBM probability with the $nY$ visible variables and the $M$ hidden variables is given by: $$P_{\\rm RBM} (\\sigma_1^z,\\sigma_2^z, ..., \\sigma_{nY}^z)  = \\frac{\\exp ( \\sum_{i=1}^{nY} a_i \\sigma_i^z ) \\prod_{i=1}^M \\cosh (b_i + \\sum_{j = 1}^{nY} W_{ij} \\sigma^z_j) }{ Z_{\\boldsymbol{\\lambda}}},$$\n",
        "up to a constant that does not depend on the parameters.\n",
        "\n",
        "2. Show that the KL divergence between the true probability distribution and the RBM probability we saw in class is given by:\n",
        "\n",
        "$$D_{KL} (P || P_{RBM}) \\approx -H_{\\text{data}} - \\frac{1}{|D|} \\sum_{\\boldsymbol{\\sigma} \\in |D|} \\log P_{RBM}(\\boldsymbol{\\sigma}), $$\n",
        "where $\\boldsymbol{\\sigma} =  (\\sigma_1^z,\\sigma_2^z, ..., \\sigma_{nY}^z)$ and $H_{\\text{data}}$ is the entropy of the data. From this expression, deduce that minimizing the KL divergence is the same as maximizing the likelihood of the data (i.e. the product of all probabilities in the dataset).\n",
        "\n",
        "3. Using question 1 and 2, show that:\n",
        "\n",
        "$$D_{KL} (P || P_{RBM}) \\approx -H_{\\text{data}} - \\frac{1}{|D|} \\sum_{\\boldsymbol{\\sigma} \\in |D|} ( \\sum_{i=1}^{nY} a_i \\sigma_i^z  +  \\sum_{i=1}^M \\log \\cosh (b_i + \\sum_{j = 1}^{nY} W_{ij} \\sigma^z_j) ) + \\log(Z_{\\boldsymbol{\\lambda}}).$$\n",
        "Deduce the expression of the gradients of $D_{KL}$ and infer which terms is intractable to estimate in practice.\n",
        "\n",
        "You can learn more here how Contrastrive Divergence (CD) can solve the intractability issue here: https://qucumber.readthedocs.io/en/stable/_static/RBM_tutorial.pdf\n",
        "\n",
        "4.    Train the RBM for $nY=8$ and $\\delta=1.14$. How do various hyperparameters affect the quality of your reconstruction?\n",
        "5.    Train the RBM on larger system size data (try at least up to 16). Adjust your hyperparameters to ensure high quality reconstruction. Plot the number of hidden units required for good representation as a function of $nY$.\n",
        "6.   Refer to the QuCumber tutorial on [sampling and calculating observables](https://github.com/PIQuIL/QuCumber/blob/master/examples/Tutorial4_DataGeneration_CalculateObservables/tutorial_sampling_observables.ipynb).\n",
        "Calculate the off-diagonal observable $\\langle \\sigma_x \\rangle$ (the in-plane magnetization).\n",
        "In what limits is it possible to confirm your result?\n",
        "\n",
        "**Additional \"bonus\" challenge exercises:**\n",
        "\n",
        "You likely won't have time to complete these exercises during the tutorial but are encouraged to try them afterwards if you are interested.\n",
        "\n",
        "1.   Calculate the second Renyi entropy $S_2$ as a function of the size of a sub-region A.\n",
        "Try for one detuning parameter far away from criticality, and one close to criticality.\n",
        "2.   At the critical point, extract the central charge $c$ of the Conformal Field Theory (CFT) corresponding to the critical detuning.\n",
        "Extract for different finite-size lattices, and extrapolate.\n",
        "How does your result compare to the theoretical value?\n",
        "\n"
      ],
      "metadata": {
        "id": "R8RNil_HG-GQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Code"
      ],
      "metadata": {
        "id": "G1eh9jt1R4Cy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Run to install qucumber (version 1.3.3):\n",
        "!pip install qucumber"
      ],
      "metadata": {
        "id": "WJiHezhZoLic"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# First we import the libraries\n",
        "# Please make sure you have the required libraries.\n",
        "# You can use pip or conda to get them.\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from qucumber.nn_states import PositiveWaveFunction\n",
        "from qucumber.callbacks import MetricEvaluator\n",
        "\n",
        "import qucumber.utils.training_statistics as ts\n",
        "import qucumber.utils.data as data\n",
        "import qucumber\n",
        "\n",
        "import torch\n",
        "\n",
        "# set random seed on cpu but not gpu, as gpu is not used\n",
        "qucumber.set_random_seed(1234, cpu=True, gpu=False)"
      ],
      "metadata": {
        "id": "4UCxoqp8m70I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now we get the training data\n",
        "# Training data is given in the data/nY=8/ directory for each delta\n",
        "# in the '...samples.csv' files.\n",
        "# So the delta needs to be specified below\n",
        "\n",
        "#-------------------- Specify delta and nY ---------------------#\n",
        "delta = \"1.14\"\n",
        "nY = \"8\" # nY refers to the number of atoms in the array\n",
        "# For the nY = 8 system case:\n",
        "# delta is any of 1.00, 1.02, 1.04, 1.06, 1.08, 1.10, 1.12, 1.14, 1.16, 1.18, 1.20\n",
        "# For nY > 8:\n",
        "# delta is any of 1.00, 1.04, 1.08, 1.12, 1.16, 1.20, 1.28\n",
        "#---------------------------------------------------------------#\n",
        "\n",
        "train_data_file = \"δ=\"+delta+\"_samples.csv\"\n",
        "link_name = \"https://raw.githubusercontent.com/PIQuIL/EssiQQurke/main/data/nY=\"+nY+\"/\"+train_data_file\n",
        "!wget \"$link_name\" #download data to Google Colab\n",
        "\n",
        "train_data = data.load_data(train_data_file)\n",
        "\n",
        "# The training data is stored in train_data[0]\n",
        "# and the dimension of the data is:\n",
        "train_data[0].shape"
      ],
      "metadata": {
        "id": "rfgVYCMWHOBc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# So now we have the training data. Our goal is to train a\n",
        "# Restricted Boltzman Machine using this training data. We use\n",
        "# QuCumber to create an instance of an RBM. First we need to specify the\n",
        "# number of visible nodes (nv) and number of higgen nodes (nh).\n",
        "# As we have an array of 8 atoms, we have 8 inputs and so nv = 8\n",
        "nv = train_data[0].shape[-1]\n",
        "\n",
        "# Number of hidden nodes of an RBM is a hyperparameter which depends on the\n",
        "# data we are using and which can be varied to get optimal result.\n",
        "nh = 2\n",
        "\n",
        "# Finally we create an RBM with nv visible nodes and nh  hidden nodes.\n",
        "nn_state = PositiveWaveFunction(num_visible=nv, num_hidden=nh, gpu=False)"
      ],
      "metadata": {
        "id": "ksViYRUfMQNE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Below we have more hyperparameters of the RBM model. Like the number of\n",
        "# hidden nodes, the parameters below can be varied to get optimal results.\n",
        "# The following hyperparameters seemed to work quite well. Note that when\n",
        "# you have different data, then different values of the hyperparameter will give\n",
        "# better solutions.\n",
        "# Further description of the parameters (if you are curious) is in:\n",
        "# https://qucumber.readthedocs.io/en/stable/quantum_states.html?highlight=fit#qucumber.nn_states.PositiveWaveFunction.fit\n",
        "\n",
        "epochs = 500\n",
        "pbs = 100 # batch size used for the positve phase term\n",
        "nbs = pbs # batch size used for the negative phase term\n",
        "lr = 0.001 # For nY > 8 systems lr = 0.0065 can be used as it works quite well.\n",
        "k = 10\n",
        "\n",
        "# Now we train our RBM using the above parameters.\n",
        "# NOTE: the training process will take 1-3 minutes\n",
        "\n",
        "nn_state.fit(\n",
        "    train_data[0],\n",
        "    epochs=epochs,\n",
        "    pos_batch_size=pbs,\n",
        "    neg_batch_size=nbs,\n",
        "    lr=lr,\n",
        "    k=k,\n",
        "    time=True,\n",
        ")"
      ],
      "metadata": {
        "id": "ojqLkj6SjHXo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# After training is complete, we save the parameters of the trained RBM below\n",
        "# as rydberg_data.pt\n",
        "nn_state.save(\"rydberg_data.pt\")\n",
        "torch.load(\"rydberg_data.pt\")\n",
        "# Below we have the parameters (weights and biases) of the trained RBM:"
      ],
      "metadata": {
        "id": "IaXPonp7On-y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now we have our trained RBM. Here we reconstruct the wavefunction by sampling from the RBM.\n",
        "# Let us see step by step how it works -\n",
        "\n",
        "# The first step is to sample from our trained RBM using QuCumber.\n",
        "# We then get num_samples samples which is stored in the variable 'samples'\n",
        "num_samples = 10000\n",
        "samples = nn_state.sample(num_samples = num_samples , k = 10)\n",
        "\n",
        "# Now we print out the samples in 'output/reconstructedSample.txt'\n",
        "sampleList = samples.tolist() # convert to list for convenience\n",
        "sampleList\n",
        "with open('reconstructedSample.txt', 'w') as fp:\n",
        "    for item in sampleList:\n",
        "        fp.write(\"%s\\n\" % item)\n"
      ],
      "metadata": {
        "id": "pfCpSmZrPBR-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "######## OPTIONAL CELL ########\n",
        "\n",
        "## -------------------------------------------------------------------- ##\n",
        "## This block of code computes amplitudes. For nY > 8, it is not necessary\n",
        "## to run this block as computation takes a lot of time.\n",
        "## -------------------------------------------------------------------- ##\n",
        "\n",
        "# From the samples we obtain the amplitudes of each of the basis states.\n",
        "# Note that here we have an 8 atom array. Hence, there are 2^8 basis states\n",
        "# which are: |00000000>, |00000001>, ..., |11111111>\n",
        "\n",
        "# Now say X is any of the states from {|00000000>, |00000001>, ..., |11111111>}\n",
        "# Now, the amplitude of a state X is computed by taking the\n",
        "# square root of the number of states X present in\n",
        "# our produced sample in 'output/reconstructedSample.txt'.\n",
        "\n",
        "# Therefore the reconstructed sample is like:\n",
        "#    |psi> = amplitudeList[0] |00000000> + amplitudeList[1] |00000001> + ... + amplitudeList[255] |11111111>\n",
        "# where amplitudeList is defined below.\n",
        "\n",
        "# The following functions below finds the amplitudes in the way described above, stores the\n",
        "# amplitudes in amplitudeList and then also\n",
        "# prints out the amplitudes in 'reconstructedSample.txt'\n",
        "\n",
        "def amplitude(sample):\n",
        "    return np.sqrt(sampleList.count(sample)/num_samples)\n",
        "\n",
        "def getBinaryString(i):\n",
        "    sites = nv # nv = 8\n",
        "    getbinary = lambda x, n: format(x, 'b').zfill(n)\n",
        "    tempStr = getbinary(i, sites)\n",
        "    return tempStr\n",
        "\n",
        "# Python code to convert string to list character-wise\n",
        "def ConvertToList(string):\n",
        "    list1=[]\n",
        "    list1[:0]=string\n",
        "    return list1\n",
        "\n",
        "amplitudeList = []\n",
        "def getAmplitude(sample):\n",
        "    for i in range (2**nv):\n",
        "        binaryString = getBinaryString(i)\n",
        "        strList = ConvertToList(binaryString)\n",
        "        tempStr = str(amplitude(list(map(int, strList))))\n",
        "        amplitudeList.append(tempStr)\n",
        "    return 0\n",
        "\n",
        "getAmplitude(sampleList)\n",
        "with open('reconstructedStateAmplitudes.txt', 'w') as fp:\n",
        "    for item in amplitudeList:\n",
        "        fp.write(\"%s\\n\" % item)"
      ],
      "metadata": {
        "id": "dh4r-ZaePyH1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# So now we have obtained the reconstructed wavefunction.\n",
        "# Now in the 'data' directory for each delta we have 1_pt_fun and 2_pt_fn\n",
        "# 1_pt_fn is the one point function and\n",
        "# 2_pt_fn is the 2 point function.\n",
        "\n",
        "# 1_pt_fn is the average occupation of each site. Note that\n",
        "# there are 8 sites as there are 8 atoms. Occupation of each site\n",
        "# refers to the proportion of atoms in the up state (state 1)\n",
        "# in each state.\n",
        "\n",
        "# Now we get average occupation of each site by finding the\n",
        "# number of atoms in the 1 state in each site and then\n",
        "# by dividing by the number of the produced samples\n",
        "occupation = [0]*nv\n",
        "for i in range(len(sampleList)):\n",
        "    j = 0\n",
        "    for j in range(nv):\n",
        "        occupation[j] = sampleList[i][j] + occupation[j]\n",
        "for i in range(nv):\n",
        "    occupation[i] = occupation[i]/len(sampleList)\n",
        "\n",
        "# Thus the average occupation per site of each site for the reconstructed state is given below\n",
        "# This data can be compared to data/nY=8/δ=delta_1_pt_fn.csv for the relevant delta\n",
        "\n",
        "# (Note: The list in data/nY=8/δ=delta_1_pt_fn.csv was obtained from\n",
        "# the sample in data/nY=8/δ=delta_samples.csv)\n",
        "\n",
        "# Thus the data in 'occupation' and 'data/nY=8/δ=delta_1_pt_fn.csv' are expected to be close (which they are)\n",
        "occupation"
      ],
      "metadata": {
        "id": "IS9LF6aRP8Kc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now we look at the 2 point function\n",
        "# 2 point function is the covariance matrix for occupations.\n",
        "# It is found by 2_pt_fn = outerProdT1 - OuterProdT2\n",
        "\n",
        "# outerProdT1 is the average of the outer product of the spin vectors with themselves\n",
        "# So we first find the sum of the outerproducts of the spin vectors with themselves.\n",
        "# Then we take the average\n",
        "outerProdT1 = np.zeros((nv,nv))\n",
        "for i in range(len(sampleList)):\n",
        "    outerProdT1 = outerProdT1 + np.outer(sampleList[i], sampleList[i])\n",
        "outerProdT1 = outerProdT1/len(sampleList)\n",
        "\n",
        "# outerProd2 is simply the outer product of the occupation vector\n",
        "# with itself. Note that we already found the occupation vector for the\n",
        "# one point function\n",
        "\n",
        "outerProdT2 = np.outer(occupation,occupation)\n",
        "outerProdT2\n",
        "\n",
        "#Hence we have:\n",
        "TwoPointFunc = outerProdT1 - outerProdT2\n",
        "\n",
        "# The TwoPointFunction data for the reconstructed state is given below.\n",
        "# This matrix can be compared to data/nY=8/δ=delta_2_pt_fn.csv for the relevant delta\n",
        "\n",
        "# (Note: The matrix in data/nY=8/δ=delta_2_pt_fn.csv was obtained from\n",
        "# the sample in data/nY=8/δ=delta_samples.csv)\n",
        "\n",
        "# Thus the matrix in 'TwoFuncPoint' and 'data/nY=8/δ=delta_2_pt_fn.csv' are expected\n",
        "# to be nearly equal (which they are)\n",
        "TwoPointFunc"
      ],
      "metadata": {
        "id": "ngvEchkdP_se"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 5"
      ],
      "metadata": {
        "id": "Gh8L7PDHErck"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Answer question 5 here"
      ],
      "metadata": {
        "id": "wWFtqrU3EsVO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 6"
      ],
      "metadata": {
        "id": "M-A7MyfmE1WF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Answer question 6 here"
      ],
      "metadata": {
        "id": "347GxLiCE1WH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}